{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from matplotlib import pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# загружаем класс pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# загружаем классы для подготовки данных\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "# загружаем класс для работы с пропусками\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# загружаем функцию для работы с метриками\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# импортируем класс RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# загружаем нужные модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "#Фиксируем константу для рандомизации\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# импортируем библиотеки для работы с текстом\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59234</th>\n",
       "      <td>59300</td>\n",
       "      <td>Sorry I have been unblocked already. It was no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82080</th>\n",
       "      <td>82156</td>\n",
       "      <td>Some of the people, places or things you have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>12327</td>\n",
       "      <td>\"\\nNothing wrong with that portrait, but she w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148756</th>\n",
       "      <td>148912</td>\n",
       "      <td>\"\\n\\nTrolling by Bogdan and Constantzeanu\\nBul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85442</th>\n",
       "      <td>85523</td>\n",
       "      <td>Rumor\\nUntil Nick himself confirms this rumor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "59234        59300  Sorry I have been unblocked already. It was no...      0\n",
       "82080        82156  Some of the people, places or things you have ...      0\n",
       "12313        12327  \"\\nNothing wrong with that portrait, but she w...      0\n",
       "148756      148912  \"\\n\\nTrolling by Bogdan and Constantzeanu\\nBul...      0\n",
       "85442        85523  Rumor\\nUntil Nick himself confirms this rumor ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классах явный дисбаланс - это нужно будет учитывать при обучении и классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов и пропусков в данных нет. Перейдём к их предобработке и трансформации, лишний стоблец удалим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107169</th>\n",
       "      <td>Since when do staffers have the right to have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911</th>\n",
       "      <td>Thank you for agreeing with me and taking the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152502</th>\n",
       "      <td>Justification to add new proof, using Bézout's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46534</th>\n",
       "      <td>Thanks and a Suggestion \\n\\nThank you for your...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39513</th>\n",
       "      <td>\"\\n\\nThank you, CrohnieGal!\\nI'm still learnin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "107169  Since when do staffers have the right to have ...      0\n",
       "35911   Thank you for agreeing with me and taking the ...      0\n",
       "152502  Justification to add new proof, using Bézout's...      0\n",
       "46534   Thanks and a Suggestion \\n\\nThank you for your...      0\n",
       "39513   \"\\n\\nThank you, CrohnieGal!\\nI'm still learnin...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала лемматизируем текст. Сначала избавимся от посторонних символос с помощью регулярных выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z]',\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww  He matches this background colour I m s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man  I m really not trying to edit war  It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You  sir  are my hero  Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D aww  He matches this background colour I m s...  \n",
       "2  Hey man  I m really not trying to edit war  It...  \n",
       "3    More I can t make any real suggestions on im...  \n",
       "4  You  sir  are my hero  Any chance you remember...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее используем специальный инструмент для лемматизации текста на английском языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['lemm_text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(w.lower()) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем стоп-слова для улучшения качества признакого описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words = list(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим данные на тестовую и тренировочную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(corpus,data['toxic'],test_size=0.25,random_state=RANDOM_STATE,stratify=data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицу TF-IDF для более качесвенного признакового описания постов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пайплайн для обучения нескольких моделей кросс-валидацией с подбором гиперпараметров. Модели классфикации: Логистическая регрессия, решающее дерево, метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipe_final = Pipeline(\n",
    "[\n",
    "    ('models',LogisticRegression( random_state=RANDOM_STATE, \n",
    "            solver='liblinear',class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_distr = [\n",
    "    {\n",
    "    'models' :[LogisticRegression( random_state=RANDOM_STATE, \n",
    "            solver='liblinear',class_weight='balanced')],\n",
    "    'models__penalty':['l1','l2'],\n",
    "    'models__C':range(1,20,5)\n",
    "        \n",
    "    },\n",
    "\n",
    "    {\n",
    "      \n",
    "    'models':[KNeighborsClassifier()],\n",
    "    'models__n_neighbors':[10,20]\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'models': [DecisionTreeClassifier(random_state=RANDOM_STATE,class_weight='balanced')],\n",
    "        'models__max_depth': [2,5]\n",
    "\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models',\n",
      "                 LogisticRegression(C=11, class_weight='balanced',\n",
      "                                    random_state=42, solver='liblinear'))])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.7622460466847006\n"
     ]
    }
   ],
   "source": [
    "randomized_search = RandomizedSearchCV(\n",
    "pipe_final,\n",
    "param_distributions=param_distr,\n",
    "scoring='f1',\n",
    "random_state=RANDOM_STATE,\n",
    "n_jobs=-1)\n",
    "\n",
    "randomized_search.fit(tf_idf_train,y_train)\n",
    "print('Лучшая модель и её параметры:\\n\\n', randomized_search.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', randomized_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась модель логистической регрессии. Проверим метрику f_score на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7611420612813371"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = randomized_search.predict(tf_idf_test)\n",
    "f1_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе решения задачи по классификации комментариев на \"токсичные\" и \"нетоксичные\" мной были сделаны следующие шаги и выводы:\n",
    "    \n",
    "* Загружены и подготовлены данные\n",
    "* Произведена лемматизация данных и трансформация в матрицу TF_IDF\n",
    "* Обучены насеолько моделей классификации с разными гиперпараметрами и получена лучшая\n",
    "\n",
    "По итогу окзалось, что лучшей моделью по предсказанию классов стала модель Логистической регрессии, с метрикой F1 на тестовой выборке в 0.76, что соответствует требованию заказчика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1547,
    "start_time": "2024-06-03T18:29:13.536Z"
   },
   {
    "duration": 186,
    "start_time": "2024-06-03T18:29:22.957Z"
   },
   {
    "duration": 2290,
    "start_time": "2024-06-03T18:29:34.145Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-03T18:29:42.523Z"
   },
   {
    "duration": 1367,
    "start_time": "2024-06-03T18:33:26.703Z"
   },
   {
    "duration": 888,
    "start_time": "2024-06-03T18:33:28.072Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-03T18:33:28.961Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-03T18:33:28.973Z"
   },
   {
    "duration": 28,
    "start_time": "2024-06-03T18:33:28.980Z"
   },
   {
    "duration": 237,
    "start_time": "2024-06-03T18:33:29.009Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-03T18:33:29.247Z"
   },
   {
    "duration": 21,
    "start_time": "2024-06-03T18:33:29.251Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-03T18:33:29.273Z"
   },
   {
    "duration": 160,
    "start_time": "2024-06-03T18:33:29.279Z"
   },
   {
    "duration": 1041,
    "start_time": "2024-06-03T18:33:29.441Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.484Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.485Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.486Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.487Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.488Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.489Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.490Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.491Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-03T18:33:30.492Z"
   },
   {
    "duration": 1391,
    "start_time": "2024-06-03T18:35:27.575Z"
   },
   {
    "duration": 888,
    "start_time": "2024-06-03T18:35:28.968Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-03T18:35:29.858Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-03T18:35:29.871Z"
   },
   {
    "duration": 62,
    "start_time": "2024-06-03T18:35:29.897Z"
   },
   {
    "duration": 225,
    "start_time": "2024-06-03T18:35:29.960Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-03T18:35:30.186Z"
   },
   {
    "duration": 106,
    "start_time": "2024-06-03T18:35:30.191Z"
   },
   {
    "duration": 3183,
    "start_time": "2024-06-03T18:35:30.299Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-03T18:35:33.483Z"
   },
   {
    "duration": 160,
    "start_time": "2024-06-03T18:35:33.492Z"
   },
   {
    "duration": 31996,
    "start_time": "2024-06-03T18:35:33.654Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-03T18:36:05.652Z"
   },
   {
    "duration": 17,
    "start_time": "2024-06-03T18:36:05.666Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-03T18:36:05.685Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-03T18:36:05.690Z"
   },
   {
    "duration": 75,
    "start_time": "2024-06-03T18:36:05.697Z"
   },
   {
    "duration": 4710,
    "start_time": "2024-06-03T18:36:05.775Z"
   },
   {
    "duration": 1449,
    "start_time": "2024-06-03T18:36:10.487Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-03T18:36:11.938Z"
   },
   {
    "duration": 1365219,
    "start_time": "2024-06-03T18:36:11.947Z"
   },
   {
    "duration": 22,
    "start_time": "2024-06-03T18:58:57.168Z"
   },
   {
    "duration": 1656,
    "start_time": "2024-06-04T09:11:34.591Z"
   },
   {
    "duration": 2286,
    "start_time": "2024-06-04T09:11:36.249Z"
   },
   {
    "duration": 66,
    "start_time": "2024-06-04T09:11:38.536Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-04T09:11:38.603Z"
   },
   {
    "duration": 74,
    "start_time": "2024-06-04T09:11:38.612Z"
   },
   {
    "duration": 331,
    "start_time": "2024-06-04T09:11:38.688Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-04T09:11:39.021Z"
   },
   {
    "duration": 20,
    "start_time": "2024-06-04T09:11:39.026Z"
   },
   {
    "duration": 3204,
    "start_time": "2024-06-04T09:11:39.048Z"
   },
   {
    "duration": 8,
    "start_time": "2024-06-04T09:11:42.254Z"
   },
   {
    "duration": 167,
    "start_time": "2024-06-04T09:11:42.263Z"
   },
   {
    "duration": 1417,
    "start_time": "2024-06-04T09:12:04.129Z"
   },
   {
    "duration": 932,
    "start_time": "2024-06-04T09:12:05.548Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-04T09:12:06.482Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-04T09:12:06.494Z"
   },
   {
    "duration": 24,
    "start_time": "2024-06-04T09:12:06.514Z"
   },
   {
    "duration": 259,
    "start_time": "2024-06-04T09:12:06.540Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-04T09:12:06.800Z"
   },
   {
    "duration": 22,
    "start_time": "2024-06-04T09:12:06.811Z"
   },
   {
    "duration": 3108,
    "start_time": "2024-06-04T09:12:06.834Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-04T09:12:09.944Z"
   },
   {
    "duration": 157,
    "start_time": "2024-06-04T09:12:09.953Z"
   },
   {
    "duration": 34548,
    "start_time": "2024-06-04T09:12:10.112Z"
   },
   {
    "duration": 2,
    "start_time": "2024-06-04T09:12:44.662Z"
   },
   {
    "duration": 19,
    "start_time": "2024-06-04T09:12:44.666Z"
   },
   {
    "duration": 11,
    "start_time": "2024-06-04T09:12:44.687Z"
   },
   {
    "duration": 23,
    "start_time": "2024-06-04T09:12:44.699Z"
   },
   {
    "duration": 74,
    "start_time": "2024-06-04T09:12:44.723Z"
   },
   {
    "duration": 4704,
    "start_time": "2024-06-04T09:12:44.799Z"
   },
   {
    "duration": 1494,
    "start_time": "2024-06-04T09:12:49.505Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-04T09:12:51.000Z"
   },
   {
    "duration": 1316416,
    "start_time": "2024-06-04T09:12:51.006Z"
   },
   {
    "duration": 18,
    "start_time": "2024-06-04T09:34:47.424Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
